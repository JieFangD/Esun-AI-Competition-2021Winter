{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d6af27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pickle import load, dump\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d152200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_data_path = './Data/tbrain_cc_training_48tags_hash_final.csv'\n",
    "raw_data_path = './Data/chid/10181291.csv'\n",
    "df = pd.read_csv(raw_data_path)\n",
    "df = df.replace(np.nan, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f8ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.at[df['shop_tag'] == 'other', 'shop_tag'] = '0'\n",
    "df['shop_tag'] = df['shop_tag'].astype('int8')\n",
    "\n",
    "predictable_classes = np.array([2,6,10,12,13,15,18,19,21,22,25,26,36,37,39,48])\n",
    "class2idx = np.zeros(49, dtype=int)\n",
    "i = 0\n",
    "for c in predictable_classes:\n",
    "    class2idx[c] = i\n",
    "    i += 1\n",
    "predictable_classes_sort_by_freq = np.array([37, 15, 36, 10, 2, 48, 12, 19, 25, 6, 18, 13, 22, 39, 21, 26])\n",
    "predictable_classes_sort_by_amt = np.array([39, 10, 2, 37, 15, 36, 48, 19, 12, 6, 18, 26, 25, 21, 13, 22])\n",
    "\n",
    "# consumer_ids, num_ids = np.unique(df['chid'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a2880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e3d907b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadDataset(Dataset):\n",
    "    def __init__(self, chid, less_class=False):\n",
    "        self.chid = chid\n",
    "        self.less_class = less_class\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.chid)\n",
    "    \n",
    "    def __getitem__(self, _idx):\n",
    "#         column = ['masts', 'educd', 'trdtp', 'naty', 'poscd', 'cuorg', 'gender_code', 'age', 'primary_card']\n",
    "#         column = ['masts', 'educd', 'trdtp', 'naty', 'poscd', 'cuorg', 'slam', 'gender_code', 'age', 'primary_card']\n",
    "        column = ['masts', 'educd', 'naty', 'gender_code', 'age', 'primary_card']\n",
    "        try:\n",
    "            df_id = pd.read_csv('Data/chid/'+str(self.chid[_idx])+'.csv')\n",
    "        except:\n",
    "            print(_idx)\n",
    "        data = np.zeros((24,49,10))\n",
    "        for i in range(1,24+1):\n",
    "            idx = (df_id['dt'] == i)\n",
    "            df_id_idx = df_id[idx]\n",
    "            shop_tag = df_id_idx['shop_tag'].to_numpy()\n",
    "            txn_amt = df_id_idx['txn_amt'].to_numpy()\n",
    "            txn_cnt = df_id_idx['txn_cnt'].to_numpy()\n",
    "            domestic_offline_cnt = df_id_idx['domestic_offline_cnt'].to_numpy()\n",
    "            domestic_online_cnt = df_id_idx['domestic_online_cnt'].to_numpy()\n",
    "            overseas_offline_cnt = df_id_idx['overseas_offline_cnt'].to_numpy()\n",
    "            overseas_online_cnt = df_id_idx['overseas_online_cnt'].to_numpy()\n",
    "            domestic_offline_amt_pct = df_id_idx['domestic_offline_amt_pct'].to_numpy()\n",
    "            domestic_online_amt_pct = df_id_idx['domestic_online_amt_pct'].to_numpy()\n",
    "            overseas_offline_amt_pct = df_id_idx['overseas_offline_amt_pct'].to_numpy()\n",
    "            overseas_online_amt_pct = df_id_idx['overseas_online_amt_pct'].to_numpy()\n",
    "            data[i-1,shop_tag,0] = txn_amt\n",
    "            data[i-1,shop_tag,1] = txn_cnt\n",
    "            data[i-1,shop_tag,2] = domestic_offline_cnt\n",
    "            data[i-1,shop_tag,3] = domestic_online_cnt\n",
    "            data[i-1,shop_tag,4] = overseas_offline_cnt\n",
    "            data[i-1,shop_tag,5] = overseas_online_cnt\n",
    "            data[i-1,shop_tag,6] = domestic_offline_amt_pct\n",
    "            data[i-1,shop_tag,7] = domestic_online_amt_pct\n",
    "            data[i-1,shop_tag,8] = overseas_offline_amt_pct\n",
    "            data[i-1,shop_tag,9] = overseas_online_amt_pct\n",
    "            \n",
    "        if self.less_class:\n",
    "            data = data[:, predictable_classes]\n",
    "            class_num = len(predictable_classes)\n",
    "        else:\n",
    "            class_num = 49\n",
    "        \n",
    "        chid_data = np.tile(df_id.iloc[-1:][column].to_numpy(), (24, 1))\n",
    "        return data, chid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56864aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaddataset = LoadDataset(np.arange(10000000, 10500000), less_class=True)\n",
    "# loader = DataLoader(dataset=loaddataset, batch_size=500, shuffle=False, num_workers=40)\n",
    "\n",
    "# data_all = []\n",
    "# chid_data_all = []\n",
    "# for data, chid_data in tqdm(loader):\n",
    "#     data_all.append(data)\n",
    "#     chid_data_all.append(chid_data)\n",
    "    \n",
    "# data_all = np.concatenate(data_all, axis=0)\n",
    "# chid_data_all = np.concatenate(chid_data_all, axis=0)\n",
    "# print(data_all.shape, chid_data_all.shape)\n",
    "\n",
    "# np.save('Data/data_all.npy', data_all)\n",
    "# np.save('Data/chid_data_all.npy', chid_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5e5c100",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, chid, less_class=False):\n",
    "        self.chid = chid\n",
    "        self.less_class = less_class\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.chid)\n",
    "    \n",
    "    def __getitem__(self, _idx):\n",
    "        data = data_all[self.chid[_idx]-10000000].copy()[:,:,:6]\n",
    "        chid_data = chid_data_all[self.chid[_idx]-10000000].copy()\n",
    "        norm_pred = norm_pred_all[self.chid[_idx]-10000000].copy()\n",
    "        \n",
    "        output_data = data[:, :, 0].copy()\n",
    "        sum_data = np.cumsum(data[:,:,0], axis=0)\n",
    "        norm_data = data[:,:,0]/(np.sum(data[:,:,0], axis=1, keepdims=True) + 0.000001)\n",
    "        norm_cnt_data = data[:,:,1]/(np.sum(np.abs(data[:,:,1]), axis=1, keepdims=True) + 0.000001)\n",
    "#         norm_doff_data = data[:,:,2]/(np.sum(np.abs(data[:,:,2]), axis=1, keepdims=True) + 0.000001)\n",
    "#         norm_donl_data = data[:,:,3]/(np.sum(np.abs(data[:,:,3]), axis=1, keepdims=True) + 0.000001)\n",
    "#         norm_ooff_data = data[:,:,4]/(np.sum(np.abs(data[:,:,4]), axis=1, keepdims=True) + 0.000001)\n",
    "#         norm_oonl_data = data[:,:,5]/(np.sum(np.abs(data[:,:,5]), axis=1, keepdims=True) + 0.000001)\n",
    "        data = np.sign(data)*np.log(np.abs(data)+1)\n",
    "\n",
    "        rank = np.zeros(output_data.shape)\n",
    "        for i in range(output_data.shape[0]):\n",
    "            idx = np.where(output_data[i] != 0)[0]\n",
    "            _rank = np.argsort(output_data[i, idx]).argsort()\n",
    "            _rank = np.clip(_rank-len(_rank)+3, 0, None)\n",
    "            rank[i, idx] = _rank+12\n",
    "        rank_output = rank[1:]\n",
    "        input_data = data[:,:,:6].reshape((len(data), -1))\n",
    "\n",
    "        sum_data_rank = np.zeros(sum_data.shape)\n",
    "        for i in range(sum_data.shape[0]):\n",
    "            idx = np.where(sum_data[i] != 0)[0]\n",
    "            _rank = np.argsort(sum_data[i, idx]).argsort()\n",
    "            sum_data_rank[i, idx] = _rank+1\n",
    "        sum_data[sum_data[:,:] > 0] = np.log(sum_data[sum_data[:,:] > 0])\n",
    "#         do_data = np.hstack([norm_doff_data, norm_donl_data, norm_ooff_data, norm_oonl_data])\n",
    "        input_data = np.hstack([input_data, rank, sum_data_rank])\n",
    "#         chid_data = np.log(chid_data+1)\n",
    "        input_data = np.hstack([input_data, norm_data, norm_cnt_data, chid_data])\n",
    "        return torch.Tensor(input_data), torch.Tensor(output_data[1:]), torch.Tensor(rank_output), torch.Tensor(norm_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e3e1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = np.load('Data/data_all.npy')\n",
    "chid_data_all = np.load('Data/chid_data_all.npy')\n",
    "# chid_data_all = np.load('Data/chid_data_process.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3a958b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_pred_all = np.load('726603_ensem.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26fc5d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500000, 24, 16, 10), (500000, 24, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all.shape, chid_data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29746c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dataset = CustomDataset(np.arange(10000000, 10100000), less_class=True)\n",
    "small_valid_dataset = CustomDataset(np.arange(10000000, 10050000), less_class=True)\n",
    "small_test_dataset = CustomDataset(np.arange(10050000, 10100000), less_class=True)\n",
    "small_loader = DataLoader(dataset=small_dataset, batch_size=500, shuffle=True, num_workers=10)\n",
    "small_valid_loader = DataLoader(dataset=small_valid_dataset, batch_size=500, shuffle=False, num_workers=10)\n",
    "small_test_loader = DataLoader(dataset=small_test_dataset, batch_size=500, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "247a228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(np.arange(10000000, 10500000), less_class=True)\n",
    "loader = DataLoader(dataset=dataset, batch_size=500, shuffle=True, num_workers=10)\n",
    "test_loader = DataLoader(dataset=dataset, batch_size=500, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f4f493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 24, 166]) torch.Size([500, 23, 16]) torch.Size([500, 23, 16]) torch.Size([500, 16]) 1.7437705993652344\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t = time.time()\n",
    "xx, yy, zz, ww = next(iter(small_loader))\n",
    "print(xx.shape, yy.shape, zz.shape, ww.shape, time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e50ca513",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.rnn = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden_dim, hidden_dim*4)\n",
    "        self.out = nn.Linear(hidden_dim*4, output_dim)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.softmax = torch.nn.Softmax(dim=2)\n",
    "        self.dropout = torch.nn.Dropout(0.4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        in_dim = x.shape[0]\n",
    "        t_dim = x.shape[1]\n",
    "        out, (h_n, h_c) = self.rnn(x, None)\n",
    "        \n",
    "        out = out.reshape((in_dim*t_dim, self.hidden_dim))\n",
    "        out = self.relu(self.fc(out))\n",
    "        out = self.dropout(out)\n",
    "        out = self.out(out)\n",
    "        out = out.reshape((in_dim, t_dim, self.output_dim))\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c0c8f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "def ndcg_s(y, output):\n",
    "    y = y.cpu().numpy()\n",
    "    output = output.cpu().detach().numpy()\n",
    "    nonzero_idx = (np.sum(y, 1) != 0)\n",
    "    return ndcg_score(y[nonzero_idx], output[nonzero_idx], k=3), np.sum(nonzero_idx)\n",
    "\n",
    "def ndcg_cpu(y, output):\n",
    "    nonzero_idx = (np.sum(y, 1) != 0)\n",
    "    return ndcg_score(y[nonzero_idx], output[nonzero_idx], k=3), np.sum(nonzero_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "299bcc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_XE_NDCG_loss(output, y):\n",
    "    if len(output.shape) == 2:\n",
    "        batch, dim = output.shape\n",
    "        t = 1\n",
    "    else:\n",
    "        batch, t, dim = output.shape\n",
    "#     weight = torch.exp(torch.arange(1,t+1)/10).cuda()\n",
    "#     weight = weight/torch.sum(weight)*t\n",
    "#     weight = weight.tile((batch,))\n",
    "    output = output.reshape(-1,dim)\n",
    "    y = y.reshape(-1,dim)\n",
    "#     weight = torch.ones(len(y)).cuda()\n",
    "#     weight[torch.sum(y,1) == 0] = 0\n",
    "    gamma = torch.rand(y.shape).cuda()\n",
    "    y = (2**y-gamma)\n",
    "    y = y/torch.sum(y, dim=1, keepdim=True)\n",
    "    return torch.mean(-1*torch.sum(y*torch.log(output), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "713741bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init():\n",
    "    model = RNN(xx.shape[2], 320, 2, yy.shape[2])\n",
    "    model.cuda()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "#     optimizer = torch.optim.RMSprop(model.parameters(), lr=0.005)\n",
    "#     optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
    "    return model, optimizer, scheduler\n",
    "\n",
    "torch.manual_seed(232)\n",
    "random.seed(232)\n",
    "np.random.seed(232)\n",
    "MSE = torch.nn.MSELoss()\n",
    "model, optimizer, scheduler = init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a22a06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SoftmaxLoss(output, y, temp=1):\n",
    "    if len(output.shape) == 2:\n",
    "        batch, dim = output.shape\n",
    "        t = 1\n",
    "    else:\n",
    "        batch, t, dim = output.shape\n",
    "#     weight = torch.exp(torch.arange(1,t+1)/11.5).cuda()\n",
    "#     weight = weight/torch.sum(weight)*t\n",
    "#     weight = weight.tile((batch,))    \n",
    "    output = output.reshape(-1,dim)/temp\n",
    "    nonzero = torch.sum(y, 1) > 0\n",
    "    y = y.reshape(-1,dim)\n",
    "    y = y/(torch.sum(y, dim=1, keepdim=True) + 1e-20)\n",
    "    return torch.mean(-1*torch.sum(y*torch.log(output + 1e-20), dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29e406c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(\n",
      "  (rnn): LSTM(166, 320, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=320, out_features=1280, bias=True)\n",
      "  (out): Linear(in_features=1280, out_features=16, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (softmax): Softmax(dim=2)\n",
      "  (dropout): Dropout(p=0.4, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3819a4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b877c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===================================================================================================================\n",
       "Layer (type:depth-idx)                   Kernel Shape              Output Shape              Param #\n",
       "===================================================================================================================\n",
       "RNN                                      --                        --                        --\n",
       "├─LSTM: 1-1                              --                        [1, 24, 320]              1,446,400\n",
       "├─Linear: 1-2                            [320, 1280]               [24, 1280]                410,880\n",
       "├─ReLU: 1-3                              --                        [24, 1280]                --\n",
       "├─Dropout: 1-4                           --                        [24, 1280]                --\n",
       "├─Linear: 1-5                            [1280, 16]                [24, 16]                  20,496\n",
       "├─Softmax: 1-6                           --                        [1, 24, 16]               --\n",
       "===================================================================================================================\n",
       "Total params: 1,877,776\n",
       "Trainable params: 1,877,776\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 45.07\n",
       "===================================================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.31\n",
       "Params size (MB): 7.51\n",
       "Estimated Total Size (MB): 7.84\n",
       "==================================================================================================================="
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = RNN(xx.shape[2], 320, 2, yy.shape[2])\n",
    "batch_size = 1\n",
    "summary(model, input_size=(1,24,166), col_names=[\"kernel_size\", \"output_size\", \"num_params\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a733f90",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2213851/3691388669.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mt_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh_n\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_c\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m                 \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36mhook\u001b[0;34m(module, input, output)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                 summary[m_key][\"output_shape\"] = [\n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 summary[m_key][\"output_shape\"] = [\n\u001b[0;32m---> 23\u001b[0;31m                     \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m                 ]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'size'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2213851/3704309218.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m166\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, input_data, batch_dim, cache_forward_pass, col_names, col_width, depth, device, dtypes, row_settings, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     )\n\u001b[0;32m--> 201\u001b[0;31m     summary_list = forward_pass(\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_forward_pass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torchinfo/torchinfo.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(model, x, batch_dim, cache_forward_pass, device, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mexecuted_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary_list\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuted\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         raise RuntimeError(\n\u001b[0m\u001b[1;32m    278\u001b[0m             \u001b[0;34m\"Failed to run torchinfo. See above stack traces for more details. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;34mf\"Executed layers up to: {executed_layers}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run torchinfo. See above stack traces for more details. Executed layers up to: []"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(1,24,166))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e315025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500, 24, 166])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e43d213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "oo = model(xx.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "847e7425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.7779, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weighted_XE_NDCG_loss(oo[:,:22], zz[:,:22].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1a6f2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06260284707678863, 400)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_s(yy[:,22], oo[:,22])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf446a59",
   "metadata": {},
   "source": [
    "# Use first 100000 data for method evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7192b4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def train_kfold(dataset, test=0, n_splits=2, fn='rnn.pt'):\n",
    "    max_epoch = 20\n",
    "    patience = 3\n",
    "    pred_sum = np.zeros((len(dataset), 16))\n",
    "    pred_sum2 = np.zeros((len(dataset), 16))\n",
    "    ndcg_sum = 0\n",
    "    ndcg_list = []\n",
    "    cnt_sum = 0\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    for kfidx, (train_index, valid_index) in enumerate(kf.split(np.arange(10000000, 10000000+len(dataset)))):\n",
    "        train_subset = Subset(dataset, train_index)\n",
    "        valid_subset = Subset(dataset, valid_index)\n",
    "        train_loader = DataLoader(dataset=train_subset, batch_size=750, shuffle=True, num_workers=20)\n",
    "        valid_loader = DataLoader(dataset=valid_subset, batch_size=750, shuffle=True, num_workers=20)\n",
    "        valid_loader_ns = DataLoader(dataset=valid_subset, batch_size=750, shuffle=False, num_workers=20)\n",
    "        test_loader = DataLoader(dataset=dataset, batch_size=750, shuffle=False, num_workers=20)\n",
    "        best_ndcg = 0\n",
    "        worse = 0\n",
    "        model, optimizer, scheduler = init()\n",
    "        for _epoch in range(max_epoch):\n",
    "            train_ndcg = 0\n",
    "            valid_ndcg = 0\n",
    "            test_ndcg = 0\n",
    "            train_cnt = 0\n",
    "            valid_cnt = 0\n",
    "            test_cnt = 0\n",
    "            train_loss = 0\n",
    "            model.train()\n",
    "            for x, y_value, y, _ in tqdm(train_loader):\n",
    "                x = x.cuda()\n",
    "                y_value = y_value.cuda()\n",
    "                y = y.cuda()\n",
    "                output = model(x)\n",
    "                loss = weighted_XE_NDCG_loss(output[:,:22], y[:,:22])\n",
    "#                 loss = Amt_SoftmaxLoss(output[:,:22], y_value[:,:22], 4)\n",
    "#                 loss = ApproxNDCGLoss(output[:,:22], y[:,:22])\n",
    "#                 loss = GumbelApproxNDCGLoss(output[:,:22], y[:,:22])\n",
    "#                 loss = SoftmaxLoss(output[:,:22], y[:,:22])\n",
    "#                 loss = MSE(output[:,:22], y[:,:22])\n",
    "#                 loss = UniqueSoftmaxLoss(output[:,:22], y[:,:22])\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            for x, y_value, y, _ in tqdm(valid_loader):\n",
    "                x = x.cuda()\n",
    "                y_value = y_value.cuda()\n",
    "                y = y.cuda()\n",
    "                output = model(x)\n",
    "                loss = weighted_XE_NDCG_loss(output[:,:21], y[:,:21])\n",
    "#                 loss = Amt_SoftmaxLoss(output[:,:21], y_value[:,:21], 4)\n",
    "#                 loss = ApproxNDCGLoss(output[:,:21], y[:,:21])\n",
    "#                 loss = GumbelApproxNDCGLoss(output[:,:21], y[:,:21])\n",
    "#                 loss = SoftmaxLoss(output[:,:21], y[:,:21])\n",
    "#                 loss = MSE(output[:,:21], y[:,:21])\n",
    "#                 loss = UniqueSoftmaxLoss(output[:,:21], y[:,:21])\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                s, n = ndcg_s(y_value[:,21], output[:,21])\n",
    "                train_ndcg += s*n\n",
    "                train_cnt += n\n",
    "            model.eval()\n",
    "            for x, y_value, y, _ in tqdm(valid_loader_ns):\n",
    "                x = x.cuda()\n",
    "                y_value = y_value.cuda()\n",
    "                y = y.cuda()\n",
    "                output = model(x)\n",
    "                s, n = ndcg_s(y_value[:,21], output[:,21])\n",
    "                valid_ndcg += s*n\n",
    "                valid_cnt += n\n",
    "            if test:\n",
    "                for x, y_value, y, _ in tqdm(test_loader):\n",
    "                    x = x.cuda()\n",
    "                    y_value = y_value.cuda()\n",
    "                    y = y.cuda()\n",
    "                    output = model(x)\n",
    "                    s, n = ndcg_s(y_value[:,22], output[:,22])\n",
    "                    test_ndcg += s*n\n",
    "                    test_cnt += n\n",
    "\n",
    "            if best_ndcg < valid_ndcg:\n",
    "                best_ndcg = valid_ndcg\n",
    "                worse = 0\n",
    "                torch.save(model.state_dict(), 'Model/'+fn)\n",
    "            else:\n",
    "                if _epoch >= 5:\n",
    "                    worse += 1\n",
    "            if test:\n",
    "                print(f'KF: {kfidx}, Epoch: {_epoch:}, Train Loss: {train_loss/(len(train_loader)+len(valid_loader)):.4f}, Train NDCG: {train_ndcg/train_cnt:.4f}, Valid NDCG: {valid_ndcg/valid_cnt:.4f}, Test NDCG: {test_ndcg/test_cnt:.4f}')                \n",
    "            else:\n",
    "                print(f'KF: {kfidx}, Epoch: {_epoch:}, Train Loss: {train_loss/(len(train_loader)+len(valid_loader)):.4f}, Train NDCG: {train_ndcg/train_cnt:.4f}, Valid NDCG: {valid_ndcg/valid_cnt:.4f}')\n",
    "            scheduler.step()\n",
    "            if worse >= patience: \n",
    "                break\n",
    "\n",
    "        model.load_state_dict(torch.load('Model/'+fn))\n",
    "        model.eval()\n",
    "        pred = []\n",
    "        gt = []\n",
    "        for x, y_value, _, _ in tqdm(test_loader):\n",
    "            x = x.cuda()\n",
    "            y_value = y_value.cuda()\n",
    "            output = model(x)\n",
    "            pred.append(output[:,22].detach().cpu().numpy())\n",
    "            gt.append(y_value[:,22].cpu().numpy())\n",
    "        pred = np.concatenate(pred, axis=0)\n",
    "        gt = np.concatenate(gt, axis=0)\n",
    "        s, n = ndcg_cpu(gt, pred)\n",
    "        print(f'Test NDCG: {s:.6f}')\n",
    "        ndcg_list.append(s)\n",
    "        pred_sum += pred\n",
    "        pred_sum2 += softmax(pred, axis=1)\n",
    "    pred_sum = pred_sum/n_splits\n",
    "    s, n = ndcg_cpu(gt, pred_sum)\n",
    "    print(ndcg_list)\n",
    "    print(f'Ensemble Test NDCG: {s:.6f}')\n",
    "    pred_sum2 = pred_sum2/n_splits\n",
    "    s, n = ndcg_cpu(gt, pred_sum2)\n",
    "    print(f'Ensemble Test NDCG: {s:.6f}')\n",
    "    \n",
    "def train_kfold_sep(dataset, test=0, n_splits=2, fn='rnn.pt', windows=7):\n",
    "    max_epoch = 20\n",
    "    patience = 3\n",
    "    pred_sum = np.zeros((len(dataset), 16))\n",
    "    pred_sum2 = np.zeros((len(dataset), 16))\n",
    "    ndcg_sum = 0\n",
    "    ndcg_list = []\n",
    "    cnt_sum = 0\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    for kfidx, (train_index, valid_index) in enumerate(kf.split(np.arange(10000000, 10000000+len(dataset)))):\n",
    "        train_subset = Subset(dataset, train_index)\n",
    "        valid_subset = Subset(dataset, valid_index)\n",
    "        train_loader = DataLoader(dataset=train_subset, batch_size=750, shuffle=True, num_workers=20)\n",
    "        valid_loader = DataLoader(dataset=valid_subset, batch_size=750, shuffle=True, num_workers=20)\n",
    "        valid_loader_ns = DataLoader(dataset=valid_subset, batch_size=750, shuffle=False, num_workers=20)\n",
    "        test_loader = DataLoader(dataset=dataset, batch_size=750, shuffle=False, num_workers=20)\n",
    "        best_ndcg = 0\n",
    "        worse = 0\n",
    "        model, optimizer, scheduler = init()\n",
    "        for _epoch in range(max_epoch):\n",
    "            train_ndcg = 0\n",
    "            valid_ndcg = 0\n",
    "            test_ndcg = 0\n",
    "            train_cnt = 0\n",
    "            valid_cnt = 0\n",
    "            test_cnt = 0\n",
    "            train_loss = 0\n",
    "            model.train()\n",
    "            for x, y_value, y, _ in tqdm(train_loader):\n",
    "                x = x.cuda()\n",
    "                y_value = y_value.cuda()\n",
    "                y = y.cuda()\n",
    "                loss = 0\n",
    "                for w in range(windows, 23):\n",
    "                    output = model(x[:,w-windows:w])\n",
    "                    loss += weighted_XE_NDCG_loss(output[:,-1], y[:,w-1])\n",
    "#                     loss += MSE(output[:,-1], y[:,w-1])\n",
    "#                 loss = weighted_XE_NDCG_loss(output[:,:22], y[:,:22])\n",
    "#                 loss = Amt_SoftmaxLoss(output[:,:22], y_value[:,:22], 4)\n",
    "#                 loss = ApproxNDCGLoss(output[:,:22], y[:,:22])\n",
    "#                 loss = GumbelApproxNDCGLoss(output[:,:22], y[:,:22])\n",
    "#                 loss = SoftmaxLoss(output[:,:22], y[:,:22])\n",
    "#                 loss = MSE(output[:,:22], y[:,:22])\n",
    "#                 loss = UniqueSoftmaxLoss(output[:,:22], y[:,:22])\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "            for x, y_value, y, _ in tqdm(valid_loader):\n",
    "                x = x.cuda()\n",
    "                y_value = y_value.cuda()\n",
    "                y = y.cuda()\n",
    "                output = model(x)\n",
    "                loss = 0\n",
    "                for w in range(windows, 22):\n",
    "                    output = model(x[:,w-windows:w])\n",
    "                    loss += weighted_XE_NDCG_loss(output[:,-1], y[:,w-1])\n",
    "#                     loss += MSE(output[:,-1], y[:,w-1])\n",
    "#                 loss = weighted_XE_NDCG_loss(output[:,:21], y[:,:21])\n",
    "#                 loss = Amt_SoftmaxLoss(output[:,:21], y_value[:,:21], 4)\n",
    "#                 loss = ApproxNDCGLoss(output[:,:21], y[:,:21])\n",
    "#                 loss = GumbelApproxNDCGLoss(output[:,:21], y[:,:21])\n",
    "#                 loss = SoftmaxLoss(output[:,:21], y[:,:21])\n",
    "#                 loss = MSE(output[:,:21], y[:,:21])\n",
    "#                 loss = UniqueSoftmaxLoss(output[:,:21], y[:,:21])\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                output = model(x[:,22-windows:22])\n",
    "                s, n = ndcg_s(y_value[:,21], output[:,-1])\n",
    "                train_ndcg += s*n\n",
    "                train_cnt += n\n",
    "            model.eval()\n",
    "            for x, y_value, y, _ in tqdm(valid_loader_ns):\n",
    "                x = x.cuda()\n",
    "                y_value = y_value.cuda()\n",
    "                y = y.cuda()\n",
    "                output = model(x[:,22-windows:22])\n",
    "                s, n = ndcg_s(y_value[:,21], output[:,-1])\n",
    "#                 output = model(x)\n",
    "#                 s, n = ndcg_s(y_value[:,21], output[:,21])\n",
    "                valid_ndcg += s*n\n",
    "                valid_cnt += n\n",
    "            if test:\n",
    "                for x, y_value, y, _ in tqdm(test_loader):\n",
    "                    x = x.cuda()\n",
    "                    y_value = y_value.cuda()\n",
    "                    y = y.cuda()\n",
    "                    output = model(x)\n",
    "                    s, n = ndcg_s(y_value[:,22], output[:,22])\n",
    "                    test_ndcg += s*n\n",
    "                    test_cnt += n\n",
    "\n",
    "            if best_ndcg < valid_ndcg:\n",
    "                best_ndcg = valid_ndcg\n",
    "                worse = 0\n",
    "                torch.save(model.state_dict(), 'Model/'+fn)\n",
    "            else:\n",
    "                if _epoch >= 5:\n",
    "                    worse += 1\n",
    "            if test:\n",
    "                print(f'KF: {kfidx}, Epoch: {_epoch:}, Train Loss: {train_loss/(len(train_loader)+len(valid_loader)):.4f}, Train NDCG: {train_ndcg/train_cnt:.4f}, Valid NDCG: {valid_ndcg/valid_cnt:.4f}, Test NDCG: {test_ndcg/test_cnt:.4f}')                \n",
    "            else:\n",
    "                print(f'KF: {kfidx}, Epoch: {_epoch:}, Train Loss: {train_loss/(len(train_loader)+len(valid_loader)):.4f}, Train NDCG: {train_ndcg/train_cnt:.4f}, Valid NDCG: {valid_ndcg/valid_cnt:.4f}')\n",
    "            scheduler.step()\n",
    "            if worse >= patience: \n",
    "                break\n",
    "\n",
    "        model.load_state_dict(torch.load('Model/'+fn))\n",
    "        model.eval()\n",
    "        pred = []\n",
    "        gt = []\n",
    "        for x, y_value, _, _ in tqdm(test_loader):\n",
    "            x = x.cuda()\n",
    "            y_value = y_value.cuda()\n",
    "            output = model(x[:,23-windows:23])\n",
    "#             output = model(x)\n",
    "            pred.append(output[:,-1].detach().cpu().numpy())\n",
    "            gt.append(y_value[:,22].cpu().numpy())\n",
    "        pred = np.concatenate(pred, axis=0)\n",
    "        gt = np.concatenate(gt, axis=0)\n",
    "        s, n = ndcg_cpu(gt, pred)\n",
    "        print(f'Test NDCG: {s:.6f}')\n",
    "        ndcg_list.append(s)\n",
    "        pred_sum += pred\n",
    "        pred_sum2 += softmax(pred, axis=1)\n",
    "    pred_sum = pred_sum/n_splits\n",
    "    s, n = ndcg_cpu(gt, pred_sum)\n",
    "    print(ndcg_list)\n",
    "    print(f'Ensemble Test NDCG: {s:.6f}')\n",
    "    pred_sum2 = pred_sum2/n_splits\n",
    "    s, n = ndcg_cpu(gt, pred_sum2)\n",
    "    print(f'Ensemble Test NDCG: {s:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72d3e6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.11it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  7.30it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 0, Train Loss: 2.2186, Train NDCG: 0.7261, Valid NDCG: 0.7295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:09<00:00,  9.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.97it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 1, Train Loss: 2.1754, Train NDCG: 0.7279, Valid NDCG: 0.7301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:09<00:00,  9.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  7.15it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 2, Train Loss: 2.1705, Train NDCG: 0.7300, Valid NDCG: 0.7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00,  9.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  7.05it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 3, Train Loss: 2.1676, Train NDCG: 0.7307, Valid NDCG: 0.7305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:09<00:00,  9.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.23it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.60it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 4, Train Loss: 2.1656, Train NDCG: 0.7317, Valid NDCG: 0.7317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:09<00:00,  9.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.56it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 5, Train Loss: 2.1637, Train NDCG: 0.7328, Valid NDCG: 0.7344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.84it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 6, Train Loss: 2.1625, Train NDCG: 0.7321, Valid NDCG: 0.7354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00,  9.93it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.76it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 7, Train Loss: 2.1609, Train NDCG: 0.7319, Valid NDCG: 0.7335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00,  9.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.69it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 8, Train Loss: 2.1594, Train NDCG: 0.7323, Valid NDCG: 0.7349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  7.49it/s]\n",
      "  0%|                                                                 | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 9, Train Loss: 2.1578, Train NDCG: 0.7309, Valid NDCG: 0.7345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 134/134 [00:11<00:00, 12.13it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG: 0.708027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.73it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 0, Train Loss: 2.2702, Train NDCG: 0.7223, Valid NDCG: 0.7284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.56it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.74it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 1, Train Loss: 2.1780, Train NDCG: 0.7273, Valid NDCG: 0.7317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:09<00:00,  9.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.72it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 2, Train Loss: 2.1726, Train NDCG: 0.7287, Valid NDCG: 0.7314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.51it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.61it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 3, Train Loss: 2.1696, Train NDCG: 0.7297, Valid NDCG: 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:09<00:00,  9.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.79it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 4, Train Loss: 2.1673, Train NDCG: 0.7300, Valid NDCG: 0.7324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.56it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 5, Train Loss: 2.1655, Train NDCG: 0.7306, Valid NDCG: 0.7330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:09<00:00,  9.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.74it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 6, Train Loss: 2.1644, Train NDCG: 0.7312, Valid NDCG: 0.7316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00,  9.94it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.53it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 7, Train Loss: 2.1632, Train NDCG: 0.7315, Valid NDCG: 0.7339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.96it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 8, Train Loss: 2.1618, Train NDCG: 0.7308, Valid NDCG: 0.7343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00,  9.93it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.76it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 9, Train Loss: 2.1609, Train NDCG: 0.7307, Valid NDCG: 0.7339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.67it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 10, Train Loss: 2.1600, Train NDCG: 0.7313, Valid NDCG: 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  7.18it/s]\n",
      "  0%|                                                                 | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 11, Train Loss: 2.1589, Train NDCG: 0.7310, Valid NDCG: 0.7337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 134/134 [00:11<00:00, 11.85it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG: 0.710269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.77it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 0, Train Loss: 2.2588, Train NDCG: 0.7213, Valid NDCG: 0.7272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.02it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.82it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 1, Train Loss: 2.1780, Train NDCG: 0.7262, Valid NDCG: 0.7262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  7.38it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 2, Train Loss: 2.1720, Train NDCG: 0.7284, Valid NDCG: 0.7311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.70it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 3, Train Loss: 2.1689, Train NDCG: 0.7292, Valid NDCG: 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  8.06it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 4, Train Loss: 2.1668, Train NDCG: 0.7296, Valid NDCG: 0.7315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.70it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 5, Train Loss: 2.1653, Train NDCG: 0.7303, Valid NDCG: 0.7325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00,  9.96it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.61it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 6, Train Loss: 2.1642, Train NDCG: 0.7303, Valid NDCG: 0.7317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.28it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.79it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 7, Train Loss: 2.1632, Train NDCG: 0.7308, Valid NDCG: 0.7340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:09<00:00,  9.60it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:07<00:00,  6.23it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.84it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 8, Train Loss: 2.1619, Train NDCG: 0.7310, Valid NDCG: 0.7334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:09<00:00,  9.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.74it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.52it/s]\n",
      "  0%|                                                                  | 0/89 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 9, Train Loss: 2.1613, Train NDCG: 0.7300, Valid NDCG: 0.7338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 89/89 [00:08<00:00, 10.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:06<00:00,  6.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 45/45 [00:05<00:00,  7.77it/s]\n",
      "  0%|                                                                 | 0/134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 2, Epoch: 10, Train Loss: 2.1603, Train NDCG: 0.7312, Valid NDCG: 0.7326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 134/134 [00:11<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test NDCG: 0.711107\n",
      "[0.7080271526054656, 0.7102689241672943, 0.7111065262511872]\n",
      "Ensemble Test NDCG: 0.711800\n",
      "Ensemble Test NDCG: 0.711800\n"
     ]
    }
   ],
   "source": [
    "train_kfold(small_dataset, test=0, n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "67e89c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_kfold_sep(small_dataset, test=0, n_splits=2, windows=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28e40859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:32<00:00, 18.20it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:10<00:00,  6.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  7.57it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 0, Train Loss: 2.1858, Train NDCG: 0.7116, Valid NDCG: 0.7138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 17.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:10<00:00,  6.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:07<00:00,  8.44it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 1, Train Loss: 2.1582, Train NDCG: 0.7134, Valid NDCG: 0.7161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:34<00:00, 17.57it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:10<00:00,  6.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:07<00:00,  8.43it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 2, Train Loss: 2.1556, Train NDCG: 0.7151, Valid NDCG: 0.7161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:32<00:00, 18.23it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:10<00:00,  6.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  8.37it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 3, Train Loss: 2.1542, Train NDCG: 0.7157, Valid NDCG: 0.7189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:10<00:00,  6.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  8.02it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 4, Train Loss: 2.1531, Train NDCG: 0.7166, Valid NDCG: 0.7175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  6.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  8.35it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 5, Train Loss: 2.1522, Train NDCG: 0.7159, Valid NDCG: 0.7150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.10it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  7.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:07<00:00,  8.46it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 6, Train Loss: 2.1512, Train NDCG: 0.7159, Valid NDCG: 0.7174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:32<00:00, 18.33it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  7.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  8.36it/s]\n",
      "  0%|                                                                | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 0, Epoch: 7, Train Loss: 2.1502, Train NDCG: 0.7176, Valid NDCG: 0.7156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████| 1000/1000 [01:12<00:00, 13.81it/s]\n",
      "100%|███████████████████████████████████████████████████████| 600/600 [00:32<00:00, 18.24it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  6.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  8.19it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 0, Train Loss: 2.1736, Train NDCG: 0.7106, Valid NDCG: 0.7154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.03it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  6.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  8.22it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 1, Train Loss: 2.1577, Train NDCG: 0.7133, Valid NDCG: 0.7136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.06it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  6.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  7.71it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 2, Train Loss: 2.1552, Train NDCG: 0.7135, Valid NDCG: 0.7138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  6.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  7.80it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 3, Train Loss: 2.1537, Train NDCG: 0.7148, Valid NDCG: 0.7148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  6.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  7.51it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 4, Train Loss: 2.1525, Train NDCG: 0.7145, Valid NDCG: 0.7185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.07it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  6.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  8.24it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 5, Train Loss: 2.1516, Train NDCG: 0.7161, Valid NDCG: 0.7151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.11it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:10<00:00,  6.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  7.81it/s]\n",
      "  0%|                                                                 | 0/600 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 6, Train Loss: 2.1505, Train NDCG: 0.7160, Valid NDCG: 0.7162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 600/600 [00:33<00:00, 18.16it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:09<00:00,  6.95it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 67/67 [00:08<00:00,  8.16it/s]\n",
      "  0%|                                                                | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KF: 1, Epoch: 7, Train Loss: 2.1496, Train NDCG: 0.7166, Valid NDCG: 0.7178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2213851/4240804789.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mndcg_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_ndcg\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mvalid_cnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "n_splits = 10\n",
    "max_epoch = 20\n",
    "patience = 3\n",
    "pred_sum = np.zeros((500000, 16))\n",
    "pred_sum_weighted = np.zeros((500000, 16))\n",
    "ndcg_sum = 0\n",
    "ndcg_list = []\n",
    "cnt_sum = 0\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)\n",
    "for kfidx, (train_index, valid_index) in enumerate(kf.split(np.arange(10000000, 10500000))):\n",
    "    train_subset = Subset(dataset, train_index)\n",
    "    valid_subset = Subset(dataset, valid_index)\n",
    "    train_loader = DataLoader(dataset=train_subset, batch_size=750, shuffle=True, num_workers=30)\n",
    "    valid_loader = DataLoader(dataset=valid_subset, batch_size=750, shuffle=True, num_workers=30)\n",
    "    valid_loader2 = DataLoader(dataset=valid_subset, batch_size=750, shuffle=False, num_workers=30)\n",
    "    best_ndcg = 0\n",
    "    worse = 0\n",
    "    model, optimizer, scheduler = init()\n",
    "    \n",
    "    for _epoch in range(max_epoch):\n",
    "        train_ndcg = 0\n",
    "        valid_ndcg = 0\n",
    "        train_cnt = 0\n",
    "        valid_cnt = 0\n",
    "        train_loss = 0\n",
    "        model.train()\n",
    "        for x, y_value, y, z in tqdm(train_loader):\n",
    "            x = x.cuda()\n",
    "            y_value = y_value.cuda()\n",
    "            y = y.cuda()\n",
    "            z = z.cuda()\n",
    "            output = model(x)\n",
    "            loss = weighted_XE_NDCG_loss(output[:,:23], y[:,:23])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        for x, y_value, y, z in tqdm(valid_loader):\n",
    "            x = x.cuda()\n",
    "            y_value = y_value.cuda()\n",
    "            y = y.cuda()\n",
    "            z = z.cuda()\n",
    "            output = model(x)\n",
    "            loss = weighted_XE_NDCG_loss(output[:,:22], y[:,:22])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            s, n = ndcg_s(y_value[:,22], output[:,22])\n",
    "            train_ndcg += s*n\n",
    "            train_cnt += n\n",
    "            \n",
    "        model.eval()\n",
    "        for x, y_value, y, _ in tqdm(valid_loader2):\n",
    "            x = x.cuda()\n",
    "            y_value = y_value.cuda()\n",
    "            y = y.cuda()\n",
    "            output = model(x)\n",
    "            s, n = ndcg_s(y_value[:,22], output[:,22])\n",
    "            valid_ndcg += s*n\n",
    "            valid_cnt += n\n",
    "            \n",
    "        if best_ndcg < valid_ndcg:\n",
    "            best_ndcg = valid_ndcg\n",
    "            worse = 0\n",
    "            torch.save(model.state_dict(), 'Model/best.pt')\n",
    "        else:\n",
    "            if _epoch >= 5:\n",
    "                worse += 1\n",
    "        print(f'KF: {kfidx}, Epoch: {_epoch:}, Train Loss: {train_loss/(len(train_loader)+len(valid_loader)):.4f}, Train NDCG: {train_ndcg/train_cnt:.4f}, Valid NDCG: {valid_ndcg/valid_cnt:.4f}')\n",
    "        scheduler.step()\n",
    "        if worse >= patience: \n",
    "            break\n",
    "\n",
    "    model.load_state_dict(torch.load('Model/best.pt'))\n",
    "    model.eval()\n",
    "    ndcg_sum += best_ndcg\n",
    "    cnt_sum += valid_cnt\n",
    "    ndcg_list.append(best_ndcg/valid_cnt)\n",
    "    pred = []\n",
    "    for x, _, y, _ in tqdm(test_loader):\n",
    "        x = x.cuda()\n",
    "        y = y.cuda()\n",
    "        output = model(x)\n",
    "        pred.append(output[:,23].detach().cpu().numpy())\n",
    "    pred = np.concatenate(pred, axis=0)\n",
    "    pred_sum_weighted += pred*(best_ndcg/valid_cnt)\n",
    "    pred_sum += pred\n",
    "pred_sum_weighted = pred_sum_weighted/sum(ndcg_list)\n",
    "pred_sum = pred_sum/n_splits\n",
    "print(f'Valid NDCG: {ndcg_sum/cnt_sum:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91b7dacc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.7189372402328684, 0.7185490244900301]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7e263a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid NDCG: 0.718743\n"
     ]
    }
   ],
   "source": [
    "print(f'Valid NDCG: {ndcg_sum/cnt_sum:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0faf201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_results(top_3_tags_all, fn):\n",
    "    with open(fn, mode='w', newline='') as submit_file: # mode w:write \n",
    "        csv_writer = csv.writer(submit_file)\n",
    "        header = ['chid', 'top1', 'top2', 'top3']\n",
    "        csv_writer.writerow(header)\n",
    "        for ID in range(len(top_3_tags_all)):\n",
    "            row = [10000000+ID, str(top_3_tags_all[ID][0]), str(top_3_tags_all[ID][1]), str(top_3_tags_all[ID][2])]\n",
    "            csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373a16be",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_3_ind = pred_sum.argsort(axis=1)[:,-3:][:,::-1]\n",
    "top_3_tags = predictable_classes[top_3_ind]\n",
    "write_results(top_3_tags, 'Result/720565.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed63ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Result/720565.npy', pred_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
